{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision, Spring 2023 HW2\n",
    "B11705009 An-Che, Liang"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Bag-of-Words Scene Recognition\n",
    "\n",
    "### Feature representation: Tiny image\n",
    "\n",
    "![](./p1/tiny_image.png)\n",
    "\n",
    "### Feature representation: Bag of SIFT\n",
    "\n",
    "![](./p1/bag_of_sift.png)\n",
    "\n",
    "### Discussion:\n",
    "\n",
    "The steps of Tiny image Scene Recognition are:\n",
    "\n",
    "1. Resize the image to small size.\n",
    "2. Use K-Nearest Neighbor algorithm on pixel values to get images with high similarity of the test image, then use those images's label to predict the test image's label.\n",
    "\n",
    "The steps of Bag-of-Words Scene Recognition are:\n",
    "\n",
    "1. Extract features from the orignal image.\n",
    "2. Use K-means clustering to partition our features into K ( my vocab size is 1000 ) clusters in such a way that the sum of the distances between the objects and their assigned cluster center is minimized.\n",
    "3. Build BoW histogram for evey images with regard of different cluster centers.\n",
    "4. Use K-Nearest Neighbor algorithm on BoW histogram to get images with high similarity of the test image, then use those images's label to predict the test image's label.\n",
    "\n",
    "The accuracy of the Tiny image algorithm is quite low ($\\text{acc}=0.209$). I think the reason is that the classification is based on raw pixel values, but two picture in the same category could potencially have drastically different values, and two picture in different categories could have similar values as well.\n",
    "\n",
    "The accuracy of the Bag of SIFT algorithm is quite high ($\\text{acc}=0.612$). I think that's because the SIFT feature can better describe the image than the minified version of the original image (the Tiny image approach), thus yield better performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : CNN Image Classification\n",
    "\n",
    "### Performance\n",
    "The best performance of `mynet` is $\\text{acc}=0.612$, the best performance of `resnet18` is $\\text{acc}=0.907$.\n",
    "\n",
    "### Model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type=mynet\n",
      "Model architecture:\n",
      "MyNet(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters:\n",
      "586250\n",
      "Model type=resnet18\n",
      "Model architecture:\n",
      "ResNet18(\n",
      "  (resnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): Identity()\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters:\n",
      "11181642\n"
     ]
    }
   ],
   "source": [
    "from p2.model import MyNet , ResNet18\n",
    "def checkModelArchitectures(model_type):\n",
    "    print(f\"Model type={model_type}\")\n",
    "    if model_type == \"mynet\":\n",
    "        model = MyNet()\n",
    "    elif model_type == \"resnet18\":\n",
    "        model = ResNet18()\n",
    "    print(\"Model architecture:\")\n",
    "    print(model)\n",
    "    print(\"Number of parameters:\")\n",
    "    model_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(model_total_params)\n",
    "\n",
    "for model_name in [\"mynet\" , \"resnet18\"]:\n",
    "    checkModelArchitectures(model_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "#### Mynet\n",
    "\n",
    "![](./p2/experiment/mynet_2023_04_07_15_59_40_adam_da%2B_modified/log/train_accuracy_plot.png)\n",
    "![](./p2/experiment/mynet_2023_04_07_15_59_40_adam_da%2B_modified/log/val_accuracy_plot.png)\n",
    "![](./p2/experiment/mynet_2023_04_07_15_59_40_adam_da%2B_modified/log/train_loss_plot.png)\n",
    "![](./p2/experiment/mynet_2023_04_07_15_59_40_adam_da%2B_modified/log/val_loss_plot.png)\n",
    "\n",
    "#### Resnet 18\n",
    "![](./p2/experiment/resnet18_2023_04_07_15_31_38_adam_da%2B_modified/log/train_accuracy_plot.png)\n",
    "![](./p2/experiment/resnet18_2023_04_07_15_31_38_adam_da%2B_modified/log/val_accuracy_plot.png)\n",
    "![](./p2/experiment/resnet18_2023_04_07_15_31_38_adam_da%2B_modified/log/train_loss_plot.png)\n",
    "![](./p2/experiment/resnet18_2023_04_07_15_31_38_adam_da%2B_modified/log/val_loss_plot.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "On my best performing model, I used the `resnet18` model with pretrained weight and `Adam` optimizer, with that setup alone breaks the simple bassline. Then I conduct data augmentation with `transforms.RandAugment()`, I also tried to implement data augmentation by combining `transforms.RandomHorizontalFlip()`, `transforms.RandomVerticalFlip()`, `transforms.RandomRotation()`, `transforms.ColorJitter()` but yield poor performance. This setup breaks the medium bassline. Finally I tweak the architecture of `resnet18` by reducing the kernal size of the fist convolution layer from $(7,7)$ to $(3,3)$, reduce the stride from $2$ to $1$. I also remove the first max pool layer. This setup breaks the strong bassline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
