{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision, Spring 2023 HW3\n",
    "B11705009 An-Che, Liang"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Homography Estimation\n",
    "\n",
    "### Warped canvas:\n",
    "\n",
    "![](./src/output1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Marker-Based Planar AR\n",
    "\n",
    "### solve_homography(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def solve_homography(u, v):\n",
    "    \"\"\"\n",
    "    This function should return a 3-by-3 homography matrix,\n",
    "    u, v are N-by-2 matrices, representing N corresponding points for v = T(u)\n",
    "    :param u: N-by-2 source pixel location matrices\n",
    "    :param v: N-by-2 destination pixel location matrices\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    N = u.shape[0]\n",
    "    H = None\n",
    "\n",
    "    if v.shape[0] is not N:\n",
    "        print('u and v should have the same size')\n",
    "        return None\n",
    "    if N < 4:\n",
    "        print('At least 4 points should be given')\n",
    "\n",
    "    # TODO: 1.forming A\n",
    "    A = np.zeros((2*N, 9))\n",
    "    for i in range(N):\n",
    "        ux, uy = u[i]\n",
    "        vx, vy = v[i]\n",
    "        A[2*i] = np.array([ux, uy, 1, 0, 0, 0, -ux*vx, -uy*vx, -vx])\n",
    "        A[2*i+1] = np.array([0, 0, 0, ux, uy, 1, -ux*vy, -uy*vy, -vy])\n",
    "    # TODO: 2.solve H with A\n",
    "    U, S, VT = np.linalg.svd(A, full_matrices=True)\n",
    "    V = VT.T\n",
    "    h = VT[-1, :]/VT[-1, -1]\n",
    "    H = np.reshape(h, (3, 3))\n",
    "    return H"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### warping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warping(src, dst, H, ymin, ymax, xmin, xmax, direction='b'):\n",
    "    h_src, w_src, ch = src.shape\n",
    "    h_dst, w_dst, ch = dst.shape\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    # TODO: 1.meshgrid the (x,y) coordinate pairs\n",
    "    x, y = np.meshgrid(np.arange(xmin, xmax, 1),\n",
    "                       np.arange(ymin, ymax, 1), sparse=False)\n",
    "    # TODO: 2.reshape the destination pixels as N x 3 homogeneous coordinate\n",
    "    x_row = x.reshape(((xmax - xmin)*(ymax - ymin), 1))\n",
    "    y_row = y.reshape(((xmax - xmin)*(ymax - ymin), 1))\n",
    "    homogeneous_coords = np.concatenate((x_row, y_row, np.ones(\n",
    "        ((xmax-xmin)*(ymax-ymin), 1))), axis=1)\n",
    "    if direction == 'b':\n",
    "        # TODO: 3.apply H_inv to the destination pixels and retrieve (u,v) pixels, then reshape to (ymax-ymin),(xmax-xmin)\n",
    "        u = np.matmul(H_inv, homogeneous_coords.T).T\n",
    "        u = np.divide(u, u[:, 2, None])\n",
    "        ux = np.round(u[:, 0]).reshape(\n",
    "            ((ymax - ymin), (xmax - xmin))).astype(np.int32)\n",
    "        uy = np.round(u[:, 1]).reshape(\n",
    "            ((ymax - ymin), (xmax - xmin))).astype(np.int32)\n",
    "        # TODO: 4.calculate the mask of the transformed coordinate (should not exceed the boundaries of source image)\n",
    "        mask = ((0 < uy)*(uy < h_src))*((0 < ux)*(ux < w_src))\n",
    "        # TODO: 5.sample the source image with the masked and reshaped transformed coordinates\n",
    "        dst[y[mask], x[mask]] = src[uy[mask], ux[mask]]\n",
    "        # TODO: 6. assign to destination image with proper masking\n",
    "        pass\n",
    "\n",
    "    elif direction == 'f':\n",
    "        # TODO: 3.apply H to the source pixels and retrieve (u,v) pixels, then reshape to (ymax-ymin),(xmax-xmin)\n",
    "        v = np.matmul(H, homogeneous_coords.T).T\n",
    "        v = np.divide(v, v[:, 2, None])\n",
    "        vx = np.round(v[:, 0].reshape(\n",
    "            (ymax - ymin), (xmax - xmin))).astype(np.int32)\n",
    "        vy = np.round(v[:, 1].reshape(\n",
    "            (ymax-ymin), (xmax - xmin))).astype(np.int32)\n",
    "        # TODO: 4.calculate the mask of the transformed coordinate (should not exceed the boundaries of destination image)\n",
    "\n",
    "        # TODO: 5.filter the valid coordinates using previous obtained mask\n",
    "        masked_vx = np.clip(vx, 0, w_dst-1)\n",
    "        masked_vy = np.clip(vy, 0, h_dst-1)\n",
    "        # TODO: 6. assign to destination image using advanced array indicing\n",
    "        dst[masked_vy, masked_vx] = src\n",
    "\n",
    "    return dst\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation method\n",
    "\n",
    "For the sake of simplicity, I use the `np.round()` method to sample pixel value from the nearest integer coordinate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Unwarp the secret\n",
    "\n",
    "### Unwarped images:\n",
    "\n",
    "#### From `BL_secret1.png`:\n",
    "![](./src/output3_1.png)\n",
    "\n",
    "#### From `BL_secret2.png`:\n",
    "![](./src/output3_2.png)\n",
    "\n",
    "### Warped result:\n",
    "\n",
    "We can see that the two unwarped images are different. The first is sharper, with clear edges, while the second is blurred. I think the reason why is that we can see `BL_secret2.png` is distorted (the straight line on the building become curved line), and our unwarp function will try to retrieve the QR code by project it on a plane, which may cause the QR code we retrieve to be distorted as well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Panorama\n",
    "\n",
    "### Stitched panorama:\n",
    "\n",
    "![](./src/output4.png)\n",
    "\n",
    "### Can all consecutive images be stitched into a panorama?\n",
    "\n",
    "False, by reordering the images, our program cannot generate the same panorama. The reason why is that in order to stitch two image together to form a part of the whole panorama, the two image must have some overlapping features, so we can match the two images on the same plane, but if the two consecutive images don't have overlapping features, then our algorithm will fail to stitch them together, thus explains the order of the images should not be changed randomly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2023qq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
